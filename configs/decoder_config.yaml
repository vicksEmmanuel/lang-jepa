decoder:
  hidden_dim: 1536  # 2x the base model embed_dim
  num_layers: 4
  num_heads: 8
  dropout: 0.1
  max_length: 128

training:
  batch_size: 32
  learning_rate: 1e-4
  num_epochs: 10
  warmup_steps: 1000
  weight_decay: 0.01
  gradient_clip: 1.0

evaluation:
  eval_steps: 100
  save_steps: 1000
  num_samples: 5  # Number of samples to show during evaluation